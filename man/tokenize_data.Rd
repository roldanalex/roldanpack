% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize_data.R
\name{tokenize_data}
\alias{tokenize_data}
\title{Create a token dataset}
\usage{
tokenize_data(
  data,
  id,
  remove_stopwords = FALSE,
  stop_words = NULL,
  no.words = 1,
  field_search
)
}
\arguments{
\item{data}{data to be tokenized.}

\item{id}{id column from dataset.}

\item{remove_stopwords}{boolean to decide if need to remove stop words.}

\item{stop_words}{list of stopwords (vector).}

\item{no.words}{number of words to analyze (ngram).}

\item{field_search}{combined column to tokenize.}
}
\description{
This function will create a list of tokenized datasets.
}
